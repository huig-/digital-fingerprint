En este capítulo se presenta la contribución propia, un método de identificación de la fuente de adquisión de vídeos de dispositivos móviles en escenarios abiertos.

\section{Consideraciones generales}
El algoritmo desarrollado se puede divir en etapas. \\

En primer lugar se extraen los fotogrames de tipo I del vídeo puesto que contienen más información que el resto. Es posible que existan varios I-frames de escenas similares y la escena podría contaminar el ruido imponiendo el peso de la escena sobre la huella extraída de los demás fotogramas, por lo que una opción es seleccionar un subconjunto de los I-frames en base a la similitud entre ellos, de forma que los fotogramas extraídos representen sin sesgo las diferentes escenas del vídeo, para evitar que frames con la misma escena contaminen el ruido. Para esto último se utiliza el algoritmo \textit{phash} que mide el grado de similitud entre distintos frames. \\

Una vez se han obtenido los fotogramas relevantes (ya sean todos los I-frames o los key-frames) se extrae el PRNU de cada fotograma mediante el algoritmo desarrollado en \cite{ana:2015} basado en la transformada \textit{wavelet} de Daubechies y se define el sensor de la cámara como la media del ruido extraído de los frames clave. \\

El último paso corresponde con clustering jerárquico utilizando el método Ward puesto que se ha visto en las pruebas que es el que mejor resultado otorga en este contexto. De la misma forma, se ha validado experimentalmente que el método del codo es el que determina con mayor precisión el número de clusters óptimos. \\

\section{Especificación del método}
En el diagrama de cajas\ref{fig_metodo} se resume el algoritmo propuesto. En la descripción se incluye la fase de extracción de fotogramas clave como parte del algoritmo a pesar de que experimentalmente los resultados obtenidos con los I-frames son mejores, a modo de conocer los dos distintos algoritmos que se compararán en el siguiente capítulo. \\
\begin{enumerate}
\item Toma como entrada un conjunto de $n$ vídeos correspondientes a $m$ cámaras de móvil distintas.
\item \textbf{Extracción de fotogramas de tipo I}: mediante la herramienta \textit{ffprobe} se decodifica cada vídeo y se extraen los I-frames, que al haber sido comprimidos sin referenciar otros fotogramas contienen mayor grado de información que los P-frames o B-frames. Como se muestra mediante experimentos, el alto nivel de compresión de los fotogramas de tipo P y de tipo B evitan la obtención de una huella significativa a partir de estos por lo que es necesario buscar los fotogramas con menor nivel de compresión en vídeo que son los de tipo I. Aún así, la compresión de los I-frames es bastante alta en comparación a imágenes.
\item \textbf{Extracción de fotogramas clave}: para no contarminar el ruido con la escena, se deben elegir frames que representen las distintas escenas del vídeo. Para ello en primer lugar se computa el \textit{phash} de cada frame y se construye la matriz de distancias $D(i,j)$ para cada par de frames, utilizando la distancia Hamming. Para seleccionar los más disimilares se define un umbral determinado y el primer I-frame como fotograma clave. Se elijen los demás I-frames de forma que la distancia Hamming entre todos ellos sea mayor al umbral.
\item \textbf{Extracción del PRNU}: se extrae el PRNU de cada fotograma clave y se calcula el PRNU del vídeo como la media de los PRNU de los frames clave. 
\item \textbf{Matriz de distancias para clustering jerárquico}: se computa la correlación entre ruidos y se utiliza como matriz de distancias en un algoritmo de clustering jerárquico aglomerativo. Al tratarse de un escenario abierto, no se tiene una base de datos que asocia sensores a ruido PRNU por lo que es necesario agrupar los vídeos de entrada en grupos de forma que cada grupo represente un dispostivo distinto. 
\item \textbf{Elección del número de clusters óptimo}: el número óptimo de clusters se obtiene mediante el método del codo.
\end{enumerate}

A continuación se detalla el algoritmo de extracción de fotogramas clave.

\begin{algorithm}
\caption{Extracción de fotogramas clave}
\label{alg_keyframes}
\begin{algorithmic}[1]
\Statex \textbf{Input} video, secuencia de fotogramas
\Statex \textbf{Output} fotogramas clave
\State $iframes \gets extraerIframes(video)$
\State $hashes \gets phash(iframes)$
\State $dist \gets matrizDistancias(hashes)$
\State $umbral \gets mediana(dist)$ 
\State $frames\_clave \gets [0]$
\State $ult \gets 0$ 
\State $f\_candidatos \gets \{(dist(ult,j), j)\in range(1,N) \; | \; dist(ult, j) > umbral\}$ 
\While{$f\_candidatos \neq\emptyset$}
   \State $max\_dist, ult \gets \max({f\_candidatos})$
   \State $iframes\_clave \gets iframes\_clave \cup \{ult\}$
   \State $f\_candidatos \gets f\_candidatos \setminus (max\_dist, ult)$
   \State $f\_candidatos \gets \{(dist(ult,j), j)\in f\_candidatos \; | \; dist(ult, j) > umbral\}$ 
\EndWhile
\State \textbf{return} $frames\_clave$
\end{algorithmic}
\end{algorithm}

La extracción de fotogramas de tipo I se realiza mediante la herramienta \textit{ffprobe} que se compila mediante la herramienta \textit{ffmpeg}. Esta última es una colección de software libre centrada en vídeo con muchas utilidades como pueden ser grabar o decodificar. En cambio \textit{ffprobe} tiene un alcance menor y no requiere tanta carga, por lo que se ha decidido el uso de esta. En concreto, para cada vídeo se aplica el siguiente comando:

\begin{lstlisting}[language=bash, basicstyle=\small, caption=Extracción de I-frames]
ffprobe -print_format json -loglevel panic -show_frames \
-select_streams v <input_video> > <output_json>
\end{lstlisting}

que crea un fichero en formato json en el que para cada fotograma se especifican ciertos parámetros como son:
\begin{itemize}
\item \textit{media\_type}: tendrá el valor vídeo en este caso, pues se ha especificado en la opción \textit{-select\_streams} el valor 'v' que indica vídeo.
\item \textit{width}: el ancho del fotograma.
\item \textit{height}: el alto del fotograma.
\item \textit{pict\_type}: tipo de fotograma, toma los valores 'I', 'B' o 'P'. 
\end{itemize}

El primer fotograma al contener la primera escena siempre formará parte del conjunto de frames clave. Para seleccionar el próximo fotograma clave primero se genera una lista de candidatos con los frames cuya distancia al primer frame es mayor a la mediana. El de distancia máxima se a\~nade al conjunto de frames clave y se repite el proceso de generación de candidatos y elección del máximo con la particularidad de que el conjunto de candidatos de cada de la iteracción $i+1$ se intereseca con el obtenido en la intersección $i$, para evitar seleccionar fotogramas que han sido descartados en iteracciones anteriores puesto que no cumplían la condición de la mediana. \\

El umbral se ha determinado experimentalmente en base a pruebas. El $phash$ se construye a partir de $64$ píxels por lo que se obtiene un $hash$ de $64$ bits, lo que implica que la distancia Hamming máxima entre dos frames es $64$. Se ha buscado un umbral que dependa del vídeo y se ha optado por la mediana. De esta forma, como poco el $50\%$ de los frames quedarían descartados. \\
 
Los frames extraídos mediante \ref{alg_keyframes} representan las distintas escenas de un vídeo. Tras extraer el PRNU de cada uno de estos frames se define el PRNU como la media del ruido de estos, lo que constituye la entrada para el algoritmo de clustering jerárquico. \\

El algoritmo de clustering jerárquico utilizará como distancia la matriz de correlaciones con una transformación. La correlación entre el PRNU $p_1$ y $p_2$ se define como:
\begin{equation}
\rho_{p_1,p_2} = \frac{\displaystyle \mathrm{Cov}(p_1, p_2)}{\displaystyle \sigma_{p_1}\sigma_{p_2}} \nonumber
\end{equation}

Se transforma la matriz de correlaciones $\rho$ en una matriz de distancias mediante $1-\rho$ puesto que:
\begin{itemize}
\item $1-\rho$ es semipositiva.
\item En $\rho$ elementos similares toman valores cercanos a $1$, lo que implica que la distancia en ese caso tiene que ser cercana a $0$.
\item En $\rho$ valores muy distintos toman valores cercanos a $-1$, que son convertidos valores próximos a $2$, distancia máxima en $1-\rho$.
\item Las otras dos propiedades de la distancia (además de semipositividad) se satisfacen.
\end{itemize}

Para la elección del número de clusters óptimo se utiliza el método del codo puesto que otros indicadores como el coeficiente silueta o el índice de Calinski-Harabasz, que como se puede ver en los experimentos dan peores resultados en este contexto. El inconveniente del método del codo es que requiere de la inspección visual de la gráfica y por consiguiente no puede automatizarse. \\
